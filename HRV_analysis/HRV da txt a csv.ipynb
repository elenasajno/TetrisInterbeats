{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2465bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4052855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il file C:/Users/amary/Flow_experiment/HRV_analysis/subject14.txt non è stato trovato.\n"
     ]
    }
   ],
   "source": [
    "#for soggetto in range(11, 64):\n",
    "\n",
    "for soggetto in range(14, 64):\n",
    "    file_path = f\"C:/Users/amary/Flow_experiment/HRV_analysis/subject{soggetto}.txt\"\n",
    "    try:\n",
    "        data = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            pattern = re.compile(r'{.*?}')\n",
    "\n",
    "        # Variabile per memorizzare il tipo di livello attuale\n",
    "            current_level = None\n",
    "\n",
    "        # Iterare attraverso le righe del file\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "\n",
    "                # Se la riga inizia con \"starting level\", aggiornare il livello corrente\n",
    "                if line.startswith('starting level:'):\n",
    "                    current_level = line.split(':')[-1].strip()\n",
    "\n",
    "                # Se la riga inizia con \"Baseline:\" o \"Level:\", iniziare a leggere i dati\n",
    "                elif line.startswith(('Baseline:', 'Level:')):\n",
    "                    # Inizializzare un dizionario per contenere i dati del livello\n",
    "                    level_data = {'Level': current_level}\n",
    "\n",
    "                    # Se la riga inizia con \"Baseline:\", aggiungi \"baseline_\" al livello corrente\n",
    "                    if line.startswith('Baseline:'):\n",
    "                        level_data['Type'] = f'baseline_{current_level}'\n",
    "                    # Altrimenti, aggiungi \"livello_\" al livello corrente\n",
    "                    else:\n",
    "                        level_data['Type'] = f'livello_{current_level}'\n",
    "\n",
    "                    # Leggere le righe successive fino alla riga vuota\n",
    "                    while True:\n",
    "                        next_line = next(file).strip()\n",
    "                        if not next_line:\n",
    "                            break\n",
    "                        # Utilizzare espressioni regolari per trovare i dati nel formato {chiave: valore}\n",
    "                        match = re.search(pattern, next_line)\n",
    "                        if match:\n",
    "                            data_dict = eval(match.group())\n",
    "                            level_data.update(data_dict)\n",
    "\n",
    "                    # Aggiungere il dizionario dei dati alla lista\n",
    "                    data.append(level_data)\n",
    "\n",
    "            # Convertire la lista di dizionari in un DataFrame pandas\n",
    "            df = pd.DataFrame(data)\n",
    "            # Salvare il DataFrame in un file CSV\n",
    "            df.to_csv('C:/Users/amary/Flow_experiment/HRV_analysis/subject'+str(soggetto)+'.csv', index=False)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Il file {file_path} non è stato trovato.\")    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93866adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il file C:/Users/amary/Flow_experiment/HRV_analysis/subject14.txt non è stato trovato.\n",
      "Il file C:/Users/amary/Flow_experiment/HRV_analysis/subject64.txt non è stato trovato.\n"
     ]
    }
   ],
   "source": [
    "#dobbiamo fare anche le baseline!!!\n",
    "#chiaramente per soggetto 14 non c'è la baseline\n",
    "\n",
    "#for soggetto in range(11, 64):\n",
    "\n",
    "for soggetto in range(14, 65):\n",
    "    file_path = f\"C:/Users/amary/Flow_experiment/HRV_analysis/subject{soggetto}.txt\"\n",
    "    try:\n",
    "        baseline_data = {}\n",
    "        with open(file_path, 'r') as file:\n",
    "            pattern = re.compile(r'{.*?}')\n",
    "            \n",
    "                    # Flag per indicare se stiamo leggendo la parte iniziale\n",
    "            reading_baseline = False\n",
    "\n",
    "            # Iterare attraverso le righe del file\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "\n",
    "                # Se la riga contiene \"5_minutes_true_baseline\", iniziare a leggere i dati\n",
    "                if line == '5_minutes_true_baseline:':\n",
    "                    reading_baseline = True\n",
    "                    continue\n",
    "\n",
    "                # Se siamo nella parte iniziale e la riga è vuota, interrompiamo la lettura della parte iniziale\n",
    "                if reading_baseline and not line:\n",
    "                    break\n",
    "\n",
    "                # Se stiamo leggendo la parte iniziale e la riga contiene dati nel formato {chiave: valore}\n",
    "                if reading_baseline:\n",
    "                    match = re.search(pattern, line)\n",
    "                    if match:\n",
    "                        baseline_data.update(eval(match.group()))\n",
    "        # Aggiungi \"baseline_100\" come tipo per la prima riga\n",
    "        baseline_data['Type'] = 'baseline_5min'\n",
    "\n",
    "        # Aggiungi \"level\" come chiave e \"100\" come valore al dizionario\n",
    "        baseline_data['Level'] = 100\n",
    "\n",
    "        # Convertire il dizionario in un DataFrame pandas\n",
    "        df_bas = pd.DataFrame([baseline_data])\n",
    "\n",
    "        # Riordina le colonne\n",
    "        df_bas = df_bas[['Level', 'Type'] + [col for col in df.columns if col not in ['Level', 'Type']]]\n",
    "\n",
    "        # Salvare il DataFrame in un file CSV\n",
    "        df_bas.to_csv('C:/Users/amary/Flow_experiment/HRV_analysis/baseline_subject'+str(soggetto)+'.csv', index=False)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Il file {file_path} non è stato trovato.\")    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "287182d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for soggetto 14\n",
    "#fattelo a mano che fai prima\n",
    "\n",
    "file_path = \"C:/Users/amary/Flow_experiment/HRV_analysis/subject14_sololivelli.txt\"\n",
    "\n",
    "data = []\n",
    "\n",
    "# Variabile per memorizzare il tipo di livello attuale\n",
    "current_level = None\n",
    "\n",
    "# Variabile per memorizzare i dati della parte iniziale\n",
    "baseline_data = {}\n",
    "\n",
    "# Modello di ricerca per i dati\n",
    "pattern = re.compile(r'{.*?}')\n",
    "\n",
    "# Apertura del file e lettura delle righe\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Rileva il livello corrente\n",
    "        if line.startswith('starting level:'):\n",
    "            current_level = line.split(':')[-1].strip()\n",
    "        # Se la riga inizia con \"Baseline:\" o \"Level:\", iniziare a leggere i dati\n",
    "        elif line.startswith(('Baseline:', 'Level:')):\n",
    "             # Inizializzare un dizionario per contenere i dati del livello\n",
    "            level_data = {'Level': current_level}\n",
    "            #print(level_data)\n",
    "\n",
    "        # Se inizia con \"Baseline:\", leggi i dati di base\n",
    "        if line == 'Baseline:':\n",
    "            baseline_data = {}\n",
    "            # Salta le righe vuote\n",
    "            next(file)\n",
    "            next(file)\n",
    "            # Leggi i dati di base fino alla riga vuota\n",
    "            while True:\n",
    "                next_line = next(file).strip()\n",
    "                if not next_line:\n",
    "                    break\n",
    "                match = re.search(pattern, next_line)\n",
    "                if match:\n",
    "                    baseline_data.update(eval(match.group()))\n",
    "\n",
    "        # Se inizia con \"Level:\", leggi i dati del livello\n",
    "        elif line == 'Level:':\n",
    "            level_data = {'Level': current_level}\n",
    "            # Salta le righe vuote\n",
    "            next(file)\n",
    "            next(file)\n",
    "            # Leggi i dati del livello fino alla riga vuota\n",
    "            while True:\n",
    "                next_line = next(file).strip()\n",
    "                if not next_line:\n",
    "                    break\n",
    "                match = re.search(pattern, next_line)\n",
    "                if match:\n",
    "                    level_data.update(eval(match.group()))\n",
    "            # Aggiungi i dati del livello alla lista\n",
    "            data.append(level_data)\n",
    "\n",
    "     \n",
    "                    \n",
    "\n",
    "                    # Se la riga inizia con \"Baseline:\", aggiungi \"baseline_\" al livello corrente\n",
    "                    if line.startswith('Baseline:'):\n",
    "                        level_data['Type'] = f'baseline_{current_level}'\n",
    "                        #print(level_data)\n",
    "                    # Altrimenti, aggiungi \"livello_\" al livello corrente\n",
    "                    else:\n",
    "                        level_data['Type'] = f'livello_{current_level}'\n",
    "                        #print(level_data)\n",
    "                    while True:\n",
    "                        next_line = next(file).strip()\n",
    "                        if not next_line:\n",
    "                            break\n",
    "                        # Utilizzare espressioni regolari per trovare i dati nel formato {chiave: valore}\n",
    "                        match = re.search(pattern, next_line)\n",
    "                        if match:\n",
    "                            data_dict = eval(match.group())\n",
    "                            level_data.update(data_dict)\n",
    "                            #print(data_dict)\n",
    "                        # Aggiungere il dizionario dei dati alla lista\n",
    "                    data.append(level_data)\n",
    "                    #print(level_data)\n",
    "            df = pd.DataFrame(data)\n",
    "            # Salvare il DataFrame in un file CSV\n",
    "            df.to_csv('C:/Users/amary/Flow_experiment/HRV_analysis/subject'+str(soggetto)+'.csv', index=False)\n",
    "\n",
    "\n",
    "                        \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdafca6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m csv_file\u001b[38;5;241m.\u001b[39mwrite(header)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m output_data:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# Creazione della riga formattata\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLevel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_nni\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msdnn\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msdsd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnni_50\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpnni_50\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnni_20\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpnni_20\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmssd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_nni\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrange_nni\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcvsd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcvnni\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_hr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_hr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_hr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_hr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlf_hf_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfnu\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhfnu\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_power\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvlf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m     csv_file\u001b[38;5;241m.\u001b[39mwrite(row)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Type'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Percorso del file\n",
    "file_path = \"C:/Users/amary/Flow_experiment/HRV_analysis/subject14_sololivelli.txt\"\n",
    "\n",
    "# Output file CSV\n",
    "output_file = \"C:/Users/amary/Flow_experiment/HRV_analysis/output14.csv\"\n",
    "\n",
    "# Definizione di una lista per contenere le righe di dati\n",
    "output_data = []\n",
    "\n",
    "# Variabile per memorizzare il tipo di livello attuale\n",
    "current_level = None\n",
    "\n",
    "# Variabile per memorizzare i dati della parte iniziale\n",
    "baseline_data = {}\n",
    "\n",
    "# Modello di ricerca per i dati\n",
    "pattern = re.compile(r'{.*?}')\n",
    "\n",
    "# Apertura del file e lettura delle righe\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Rileva il livello corrente\n",
    "        if line.startswith('starting level:'):\n",
    "            current_level = line.split(':')[-1].strip()\n",
    "\n",
    "        # Se inizia con \"Baseline:\", leggi i dati di base\n",
    "        elif line == 'Baseline:':\n",
    "            baseline_data = {}\n",
    "            # Salta le righe vuote\n",
    "            next(file)\n",
    "            next(file)\n",
    "            # Leggi i dati di base fino alla riga vuota\n",
    "            while True:\n",
    "                next_line = next(file).strip()\n",
    "                if not next_line:\n",
    "                    break\n",
    "                match = re.search(pattern, next_line)\n",
    "                if match:\n",
    "                    baseline_data.update(eval(match.group()))\n",
    "\n",
    "        # Se inizia con \"Level:\", leggi i dati del livello\n",
    "        elif line == 'Level:':\n",
    "            # Salta le righe vuote\n",
    "            next(file)\n",
    "            next(file)\n",
    "            level_data = {'Level': current_level}\n",
    "            # Leggi i dati del livello fino alla riga vuota\n",
    "            while True:\n",
    "                next_line = next(file).strip()\n",
    "                if not next_line:\n",
    "                    break\n",
    "                match = re.search(pattern, next_line)\n",
    "                if match:\n",
    "                    data_dict = eval(match.group())\n",
    "                    level_data.update(data_dict)\n",
    "            # Aggiungi i dati del livello alla lista\n",
    "            output_data.append(level_data)\n",
    "\n",
    "# Intestazione del file CSV\n",
    "header = \"Level,Type,mean_nni,sdnn,sdsd,nni_50,pnni_50,nni_20,pnni_20,rmssd,median_nni,range_nni,cvsd,cvnni,mean_hr,max_hr,min_hr,std_hr,lf,hf,lf_hf_ratio,lfnu,hfnu,total_power,vlf\\n\"\n",
    "\n",
    "# Scrivi i dati nel file CSV\n",
    "with open(output_file, 'w') as csv_file:\n",
    "    csv_file.write(header)\n",
    "    for item in output_data:\n",
    "        # Creazione della riga formattata\n",
    "        row = f\"{item['Level']},{item['Type']},{item['mean_nni']},{item['sdnn']},{item['sdsd']},{item['nni_50']},{item['pnni_50']},{item['nni_20']},{item['pnni_20']},{item['rmssd']},{item['median_nni']},{item['range_nni']},{item['cvsd']},{item['cvnni']},{item['mean_hr']},{item['max_hr']},{item['min_hr']},{item['std_hr']},{item['lf']},{item['hf']},{item['lf_hf_ratio']},{item['lfnu']},{item['hfnu']},{item['total_power']},{item['vlf']}\\n\"\n",
    "        csv_file.write(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
